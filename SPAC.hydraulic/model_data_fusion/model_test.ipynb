{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         gpmax       p50        aa          lww        b0     sigma     calib  \\\n",
      "0  9706.619646 -1.050450  7.976073  3760.423358 -0.937349  1.604735  1.257231   \n",
      "1  2676.591533 -3.742751  5.312476  5732.178025 -0.533413  0.905992  0.949111   \n",
      "\n",
      "         bc      loglik  \n",
      "0  0.068279 -430.821241  \n",
      "1  0.104079 -282.159824  \n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# 指定pickle文件的路径\n",
    "pickle_file_path = '/Users/quan/projects/MySkill/model_data_fusion/Output/US-Me2_00.pickle'\n",
    "\n",
    "# 使用二进制模式打开pickle文件并加载内容\n",
    "with open(pickle_file_path, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# 现在,'data'变量中包含了pickle文件中的对象或数据\n",
    "print(data)\n",
    "\n",
    "# gpmax       p50        aa          lww        b0     sigma     calib         bc      loglik  \n",
    "\n",
    "# 0  9706.619646 -1.050450  7.976073  3760.423358 -0.937349  1.604735  1.257231   0  0.068279 -430.821241  \n",
    "# 1  2676.591533 -3.742751  5.312476  5732.178025 -0.533413  0.905992  0.949111   1  0.104079 -282.159824 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import uniform,norm\n",
    "import warnings; warnings.simplefilter(\"ignore\")\n",
    "\n",
    "from src.myFun import SoilRoot, InitialState, f_PM_hydraulics,dailyAvg\n",
    "from src.myFun import Constraint_p50, Constraint_b0,AMIS_proposal_constraint,AMIS_prop_loglik,ReplaceItems,SwapChains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#======= for running on server ==========\n",
    "#arrayid = int(os.environ['SLURM_ARRAY_TASK_ID']) # 0-119\n",
    "#niter = 2000\n",
    "#numchunck = 10\n",
    "#========================================\n",
    "\n",
    "#===== for running on local machine ======\n",
    "arrayid = 0\n",
    "niter = 1\n",
    "numchunck = 2\n",
    "#========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "chains_per_site = 10\n",
    "inpath = '/Users/quan/projects/MySkill/model_data_fusion/Input/'\n",
    "outpath = 'Output/'\n",
    "\n",
    "sitename = 'US-Me2'\n",
    "# Site specific parameters\n",
    "soil_texture = 2; root_type = 4\n",
    "root_depth = 2; canopy_height = 33; tower_height = 47 # in meters\n",
    "nobsinaday = 1# 48 # number of observations per day\n",
    "warmup = 60 # warmup period, days\n",
    "\n",
    "df = pd.read_csv(inpath+sitename+'.csv')[:nobsinaday*365] # use the first year to retrieve parameters, as an example\n",
    "SRparas = SoilRoot(soil_texture,root_type,root_depth,canopy_height,tower_height,24*3600/nobsinaday,1,0)\n",
    "Init = InitialState(-0.05,-0.1,-0.2,-0.1,df['SOILM'][0],df['SOILM2'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid = int(arrayid/chains_per_site)\n",
    "chainid = arrayid-fid*chains_per_site\n",
    "\n",
    "mVPD = np.mean(df['VPD'][(df['P']==0) & (df['RNET']>0)])\n",
    "discard = dailyAvg(df['P'],nobsinaday)>10/nobsinaday # rainy days\n",
    "discard[:warmup] = True # warm up period\n",
    "observed_day_valid = dailyAvg(df['ET'],nobsinaday)[~discard]\n",
    "\n",
    "varnames = ['gpmax','p50','aa','lww','b0','sigma','calib','bc']\n",
    "varid = varnames.index('sigma')\n",
    "varnames.append('loglik')\n",
    "p = int(len(varnames)-1)\n",
    "\n",
    "lowbound = np.array([1,-10,1,500,-2,0.01,0.5,SRparas.sw2])\n",
    "upbound = np.array([10000,-0.5,8,10000,0,2,1.5,SRparas.ssat2])\n",
    "\n",
    "# lowbound = np.array([1,1,1,500,1,0.01,0.5,SRparas.sw2])\n",
    "# upbound = np.array([10000,100,8,10000,100,2,1.5,SRparas.ssat2])\n",
    "\n",
    "scale = np.max(abs(np.column_stack([lowbound,upbound])),axis=1)\n",
    "\n",
    "# Initialize, sample in a rescaled world; \n",
    "# Scale is only needed when evaluating likelihood and exporting results\n",
    "lowbound = lowbound/scale\n",
    "upbound = upbound/scale\n",
    "bounds = (lowbound, upbound, scale)\n",
    "\n",
    "# Parameters of AMIS, see Ji and Schmidler \n",
    "# Temperatures used for tempering\n",
    "temps = 2**np.arange(0,6,2)                                                         \n",
    "mu = [np.mean(np.column_stack([lowbound,upbound]),axis=1) for t in temps] \n",
    "sigma = [0.5**2*np.identity(p) for t in temps]                                      \n",
    "tail_para = (mu[0],1**2*np.identity(p),0.1)\n",
    "r = 0.15                                                                           \n",
    "power = 0.1                                                                         \n",
    "K = 20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.00000000e-04, -1.00000000e+00,  1.25000000e-01,  5.00000000e-02,\n",
       "       -1.00000000e+00,  5.00000000e-03,  3.33333333e-01,  2.27858679e-01])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lowbound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#%  Forward Run\n",
    "\n",
    "#%% AMIS to find parameters\n",
    "def Gaussian_loglik(theta):\n",
    "    theta_complete = theta*scale \n",
    "    E,PSIL = f_PM_hydraulics(df,SRparas,theta_complete)\n",
    "    yhat = dailyAvg(E,nobsinaday)[~discard]*1e3\n",
    "    return np.sum(norm.logpdf(observed_day_valid,yhat,theta[varid]*scale[varid]))\n",
    "\n",
    "#%% AMIS sampling with parallel tempering\n",
    "theta = [uniform.rvs(loc=lowbound,scale=upbound-lowbound) for t in temps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.28591344 -0.13791446  0.6498779   0.90732624 -0.43188709  0.89130064\n",
      "  0.61086238  0.81981045]\n",
      "[ 0.33486473 -0.7660057   0.5174026   0.68910457 -0.62732444  0.13220543\n",
      "  0.33451908  0.55926532]\n",
      "[ 0.54592974 -0.47919838  0.14579026  0.8345152  -0.27505544  0.01902188\n",
      "  0.37111821  0.3787597 ]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(temps)):\n",
    "    print(theta[i])\n",
    "    theta[i][4] = uniform.rvs(loc=lowbound[4],scale=Constraint_b0(theta[i]*scale,mVPD)/scale[4]-lowbound[4])\n",
    "    theta[i][1] = uniform.rvs(loc=lowbound[1],scale=Constraint_p50(theta[i]*scale,mVPD)/scale[1]-lowbound[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "logp1 = np.array(list(map(Gaussian_loglik,theta)))\n",
    "\n",
    "sample = np.copy(theta[0]).reshape((-1,p))\n",
    "\n",
    "## for test\n",
    "sample1 = np.copy(theta[1]).reshape((-1,p))\n",
    "sample2= np.copy(theta[2]).reshape((-1,p))\n",
    "\n",
    "lik = np.array([np.copy(logp1[0])])\n",
    "acc = np.zeros(temps.shape)\n",
    "swapflag = np.zeros(temps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acceptance rate: [0. 0. 0.]\n",
      "Swap rate:\n",
      "[1. 1. 0.]\n",
      "Acceptance rate: [0. 0. 0.]\n",
      "Swap rate:\n",
      "[1. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "for chunckid in range(numchunck): \n",
    "    outname = outpath+sitename +'_0_'+str(chunckid).zfill(2)+'.pickle' \n",
    "    for i in range(niter):\n",
    "#        print(i)\n",
    "        acc = acc*(i+chunckid*niter)/(i+chunckid*niter+1)\n",
    "        \n",
    "        # Propose a new sample\n",
    "        theta_star = [AMIS_proposal_constraint(theta[j],mu[j],sigma[j],tail_para,bounds,mVPD) for j,t in enumerate(temps)]\n",
    "        \n",
    "        # Evalute likelihood\n",
    "        logp2 = np.array(list(map(Gaussian_loglik,theta_star))) # before tempering\n",
    "        logq2 = np.array([AMIS_prop_loglik(th,mu[j],sigma[j],tail_para) for j,th in enumerate(theta_star)])\n",
    "        logq1 = np.array([AMIS_prop_loglik(th,mu[j],sigma[j],tail_para) for j,th in enumerate(theta)])\n",
    "\n",
    "        # Accept with calculated probability\n",
    "        logA = (logp2-logp1)/temps-(logq2-logq1)\n",
    "        accept = np.log(uniform.rvs(size=len(temps)))<logA\n",
    "        acc[accept] = acc[accept]+1/(i+chunckid*niter+1)\n",
    "        \n",
    "        \n",
    "        theta = ReplaceItems(theta,theta_star,accept)\n",
    "        logp1[accept] = logp2[accept]\n",
    "        \n",
    "        # Swap between chains\n",
    "        theta,logp1,sf = SwapChains(temps,theta,logp1)\n",
    "        swapflag = np.row_stack([swapflag,sf])\n",
    "    \n",
    "        # Save the sample for T = 1, i.e., the target distribution\n",
    "        sample = np.row_stack([sample,theta[0]]) \n",
    "        lik = np.concatenate([lik,[logp1[0]]])\n",
    "        \n",
    "#        # for test\n",
    "        sample1 = np.row_stack([sample1,theta[1]])\n",
    "        sample2 = np.row_stack([sample2,theta[2]])\n",
    "\n",
    "        if np.mod(i,K)==0:\n",
    "            rn = r/((i+1+chunckid*niter)/K)**power\n",
    "            mu[0] = mu[0]+rn*np.mean(sample[-K:]-mu[0],axis=0)\n",
    "            sigma[0] = sigma[0]+rn*(np.dot(np.transpose(sample[-K:]-mu[0]),sample[-K:]-mu[0])/K-sigma[0])\n",
    "            mu[1] = mu[1]+rn*np.mean(sample1[-K:]-mu[1],axis=0)\n",
    "            sigma[1] = sigma[1]+rn*(np.dot(np.transpose(sample1[-K:]-mu[1]),sample1[-K:]-mu[1])/K-sigma[1])\n",
    "            mu[2] = mu[2]+rn*np.mean(sample2[-K:]-mu[2],axis=0)\n",
    "            sigma[2] = sigma[2]+rn*(np.dot(np.transpose(sample2[-K:]-mu[2]),sample2[-K:]-mu[2])/K-sigma[2])\n",
    "\n",
    "    \n",
    "    print('Acceptance rate: '+str(acc))\n",
    "    print('Swap rate:')\n",
    "    print(np.sum(swapflag,axis=0)/niter)\n",
    "    \n",
    "    sdf = pd.DataFrame(np.column_stack([sample*scale,lik]),columns = varnames)\n",
    "    sdf.to_pickle(outname)\n",
    "    sample = sample[-1,:]\n",
    "    lik = [lik[-1]]\n",
    "\n",
    "##   Optional: save chains at higher temperatures\n",
    "    sdf = pd.DataFrame(np.column_stack([sample1*scale]),columns = varnames[:-1])\n",
    "    sdf.to_pickle(outpath+sitename +'_1_'+str(chunckid).zfill(2)+'.pickle')\n",
    "    sdf = pd.DataFrame(np.column_stack([sample2*scale]),columns = varnames[:-1])\n",
    "    sdf.to_pickle(outpath+sitename +'_2_'+str(chunckid).zfill(2)+'.pickle')\n",
    "    sample1 = sample1[-1,:]\n",
    "    sample2 = sample2[-1,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         gpmax       p50        aa          lww        b0     sigma     calib  \\\n",
      "0  6585.872843 -8.400188  5.209073  8533.533938 -1.693088  0.835437  0.523858   \n",
      "1  6585.872843 -8.400188  5.209073  8533.533938 -1.693088  0.835437  0.523858   \n",
      "\n",
      "         bc  \n",
      "0  0.356873  \n",
      "1  0.356873  \n"
     ]
    }
   ],
   "source": [
    "# 指定pickle文件的路径\n",
    "pickle_file_path = '/Users/quan/projects/MySkill/model_data_fusion/Output/US-Me2_2_00.pickle'\n",
    "\n",
    "# 使用二进制模式打开pickle文件并加载内容\n",
    "with open(pickle_file_path, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# 现在,'data'变量中包含了pickle文件中的对象或数据\n",
    "print(data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
